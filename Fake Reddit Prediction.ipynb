{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Problem Formulation"
      ],
      "metadata": {
        "id": "d3tjNtHEpeUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The Problem is:**\n",
        "\n",
        "Each row in our data contains a title, and each title will either be categorized as fake or not. We should use text preprocessing techniques to clean the data because the problem is that it contains various word forms. "
      ],
      "metadata": {
        "id": "Apt3T-S9qpIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is the input?**\n",
        "\n",
        "\n",
        "Text column includes titles that will be classified as fake or not."
      ],
      "metadata": {
        "id": "qYyFN4mgqpQ4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is the output?**\n",
        "\n",
        "\n",
        "Probability of how much is the title classified as fake."
      ],
      "metadata": {
        "id": "BWIBwu1CqpXa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What data mining function is required?**\n",
        "\n",
        "\n",
        "*Drop duplicate*\n",
        "\n",
        "*Drop useless rows*\n",
        "\n",
        "*re.sub*\n",
        "\n",
        "*re.compile*\n",
        "\n",
        "*re.IGNORECASE*\n",
        "\n",
        "*word.lower()*\n",
        "\n",
        "*value_counts*\n",
        "\n",
        "*Steeming*\n",
        "\n",
        "*Stop words*"
      ],
      "metadata": {
        "id": "AYUe5sEBr8_S"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What could be the challenges?**\n",
        "\n",
        "\n",
        "*   The data contains various forms of words.\n",
        "\n",
        "*   The datasets have outliers values.\n",
        "\n",
        "*   predict a specific reddit post is fake news or not, by looking at its title.\n"
      ],
      "metadata": {
        "id": "1e7M8NJYsSmZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is the impact?**\n",
        "\n",
        "When I create a new system and give it a Feature, it can decide whether If a specific reddit post is fake news or not."
      ],
      "metadata": {
        "id": "rxjCJT5-tT6K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is an ideal solution?**\n",
        "\n",
        "Logistic regression model with word-level victorizer and GridSearchCV."
      ],
      "metadata": {
        "id": "-lbBlk3YuGhp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What is the experimental protocol used and how was it carried out?**\n",
        "\n",
        "tf-idf Char level vectorizer and tf-idf Word level vectorizer. Both are good and each one of them is good with sort of data. We cannot decide which is better than other, It depends only on trained data."
      ],
      "metadata": {
        "id": "uFwqD2TSuJLh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**What preprocessing steps are used?**\n",
        "\n",
        "\n",
        "\n",
        "*   drop duplicate rows and clear data that includes false label.\n",
        "\n",
        "*   cleared stop words.\n",
        "\n",
        "*   cleared operations signs to make classifying easier.\n",
        "*   Convert upper cases to lower.\n",
        "\n",
        "\n",
        "*   Use tf-idf with word vectorizer and char vectorizer.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "zPRDJSvRwJWM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **What is the difference between Character n-gram and Word n-gram? Which one tends to suffer more from the OOV issue?**\n",
        "\n",
        "Word n-grams compute how much a word is repeated depending on the chosen number, but character n-grams compute how much a character is repeated depending on the chosen number.\n",
        "\n",
        "Character Tokenizers effectively handle OOV words by maintaining the word's information. The OOV word is broken down into characters, and these characters are used to represent the word. Additionally, it restricts the vocabulary's scope. since every character in the 26 vocabulary words is different."
      ],
      "metadata": {
        "id": "rrzk8gPZwevq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **What is the difference between stop word removal and stemming? Are these techniques language-dependent?**\n",
        "\n",
        " \n",
        "removes words that don't significantly contribute to the text's meaning.\n",
        "\n",
        "similar to (the, is, in, for, where, when, to, at, etc.).\n",
        "\n",
        "Steeming, a text normalization technique, removes the beginning or end of a word by taking into account a list of frequently occurring prefixes or suffixes that might be present in that word.\n",
        "\n",
        "The process of removing the suffixes (such as \"ing,\" \"ly,\" \"es,\" and \"s\") from a word is based on simple rules.\n",
        "\n",
        "It heavily depends on the task that we are completing.\n"
      ],
      "metadata": {
        "id": "TENjwjG4w3iy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **Is tokenization techniques language dependent? Why?**\n",
        "\n",
        "Yes, tokenization divides the original text into manageable pieces. Tokenization divides the original text into tokens, which are words and sentences. These tokens aid in context comprehension or model development for NLP. By examining the word order in the text, tokenization aids in interpreting the meaning of the text."
      ],
      "metadata": {
        "id": "k2KybNg5we1a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " **What is the difference between count vectorizer and tf-idf vectorizer? Would it be feasible to use all possible n-grams? If not, how should you select them?**\n",
        "\n",
        "\n",
        "Count Vectorizer is a way to convert a given set of strings into a frequency representation.\n",
        "\n",
        "The statistic known as Term Frequency — Inverse Document Frequency (TF-IDF) seeks to more accurately define a word's significance for a document while also taking into account the relationship to other documents from the same corpus.\n"
      ],
      "metadata": {
        "id": "KlPzKcQ4xCWT"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mb0Zu-5XuqzW"
      },
      "source": [
        "#**scenario_1** \n",
        "\n",
        "using the first processing technique(Lemmatization)\n",
        "Lemmatization is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item. Lemmatization is similar to stemming but it brings context to the words. So it links words with similar meanings to one word."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gESwe_xtKaRn"
      },
      "source": [
        "#importing libraries.\n",
        "I will install a package and import several libraries."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFZBoIaTKRj-",
        "outputId": "94f273f3-9ab8-463f-f1dd-85c0d6ac1156"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.9.0-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.3/100.3 KB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.9/dist-packages (from scikit-optimize) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-optimize) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.9/dist-packages (from scikit-optimize) (1.1.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from scikit-optimize) (1.10.1)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading pyaml-21.10.1-py2.py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.9/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-21.10.1 scikit-optimize-0.9.0\n"
          ]
        }
      ],
      "source": [
        "# this line is for BayesSearchCV and using skopt package\n",
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OpgnVwc8BHGo",
        "outputId": "49c2216f-a8e9-4aa7-9be1-38e89548dd3c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: textblob in /usr/local/lib/python3.9/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.9/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (4.65.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (1.1.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (2022.10.31)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.9/dist-packages (from nltk>=3.1->textblob) (8.1.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RWlf-4HZBHGo",
        "outputId": "0c9c76a0-aced-4df5-8286-63b98e2b9eff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.9/dist-packages (1.7.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from xgboost) (1.22.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.9/dist-packages (from xgboost) (1.10.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install xgboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2jYm0k7KjF-",
        "outputId": "907207ef-e784-4e3e-b114-90fb8bbd4418"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from bokeh.io import output_notebook\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer #TF-IDF or ( Term Frequency(TF) — Inverse Dense Frequency(IDF) )is a technique which is used to find meaning of sentences consisting of words and cancels out the incapabilities of Bag of Words technique which is good for text classification or for helping a machine read words in numbers.\n",
        "from nltk.tokenize import word_tokenize #method to split a sentence into tokens or words\n",
        "from nltk.corpus import stopwords # In NLP and text mining applications, stop words are used to eliminate unimportant words, allowing applications to focus on the important words instead.\n",
        "from nltk.stem.snowball import SnowballStemmer #words stemming is reducing a word to its base word \n",
        "import re #A regular expression (or RE) specifies a set of strings that matches it; the functions in this module let you check if a particular string matches a given regular expression (or if a given regular expression matches a particular string, which comes down to the same thing)\n",
        "import pickle #the process of converting a Python object into a byte stream to store it in a file/database, maintain program state across sessions, or transport data over the network\n",
        "import sklearn\n",
        "import holoviews as hv #HoloViews is an open-source Python library designed to make data analysis and visualization seamless and simple\n",
        "import nltk # It provides us various text processing libraries with a lot of test datasets.\n",
        "from bokeh.io import output_notebook \n",
        "output_notebook()\n",
        "from pathlib import Path\n",
        "from textblob import TextBlob\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.corpus import wordnet\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV,RandomizedSearchCV\n",
        "from sklearn.model_selection import PredefinedSplit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9l4kijJMZyv"
      },
      "source": [
        "#Load Data\n",
        "To both read from and write to a file, you can use the built-in function open() , which takes in two parameters: file name and mode."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'll use the read csv function to read the data."
      ],
      "metadata": {
        "id": "-Np1OJQ7EZZF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "X-RRI8DSK7R9"
      },
      "outputs": [],
      "source": [
        "#load the training and testing data\n",
        "df_train= pd.read_csv('xy_train.csv',index_col='id')\n",
        "df_test = pd.read_csv('x_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "rFLUB_txLN_-",
        "outputId": "5a386fba-d307-47a7-b31d-331fe7d838cb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  label\n",
              "id                                                              \n",
              "265723  A group of friends began to volunteer at a hom...      0\n",
              "284269  British Prime Minister @Theresa_May on Nerve A...      0\n",
              "207715  In 1961, Goodyear released a kit that allows P...      0\n",
              "551106  Happy Birthday, Bob Barker! The Price Is Right...      0\n",
              "8584    Obama to Nation: 聙\"Innocent Cops and Unarmed Y...      0\n",
              "...                                                   ...    ...\n",
              "70046   Finish Sniper Simo H盲yh盲 during the invasion o...      0\n",
              "189377  Nigerian Prince Scam took $110K from Kansas ma...      1\n",
              "93486   Is It Safe To Smoke Marijuana During Pregnancy...      0\n",
              "140950  Julius Caesar upon realizing that everyone in ...      0\n",
              "34509   Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New...      1\n",
              "\n",
              "[60000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-416accde-9e0d-4b68-ac44-71bc77e2c57a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>265723</th>\n",
              "      <td>A group of friends began to volunteer at a hom...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284269</th>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve A...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207715</th>\n",
              "      <td>In 1961, Goodyear released a kit that allows P...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551106</th>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8584</th>\n",
              "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Y...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70046</th>\n",
              "      <td>Finish Sniper Simo H盲yh盲 during the invasion o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189377</th>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93486</th>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140950</th>\n",
              "      <td>Julius Caesar upon realizing that everyone in ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34509</th>\n",
              "      <td>Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-416accde-9e0d-4b68-ac44-71bc77e2c57a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-416accde-9e0d-4b68-ac44-71bc77e2c57a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-416accde-9e0d-4b68-ac44-71bc77e2c57a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "#showing the training data\n",
        "df_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "_En6J0KKLVI_",
        "outputId": "3e2d3190-b651-4a83-8c55-0d9ff7799b55"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id                                               text\n",
              "0          0                                         stargazer \n",
              "1          1                                               yeah\n",
              "2          2  PD: Phoenix car thief gets instructions from Y...\n",
              "3          3  As Trump Accuses Iran, He Has One Problem: His...\n",
              "4          4                       \"Believers\" - Hezbollah 2011\n",
              "...      ...                                                ...\n",
              "59146  59146                  Bicycle taxi drivers of New Delhi\n",
              "59147  59147  Trump blows up GOP's formula for winning House...\n",
              "59148  59148  Napoleon returns from his exile on the island ...\n",
              "59149  59149   Deep down he always wanted to be a ballet dancer\n",
              "59150  59150  Toddler miraculously survives 6-story fall lan...\n",
              "\n",
              "[59151 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6da665ec-e6c8-46aa-a0d6-ac531dfba68a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>stargazer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>yeah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>PD: Phoenix car thief gets instructions from Y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>As Trump Accuses Iran, He Has One Problem: His...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\"Believers\" - Hezbollah 2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59146</th>\n",
              "      <td>59146</td>\n",
              "      <td>Bicycle taxi drivers of New Delhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59147</th>\n",
              "      <td>59147</td>\n",
              "      <td>Trump blows up GOP's formula for winning House...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59148</th>\n",
              "      <td>59148</td>\n",
              "      <td>Napoleon returns from his exile on the island ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59149</th>\n",
              "      <td>59149</td>\n",
              "      <td>Deep down he always wanted to be a ballet dancer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59150</th>\n",
              "      <td>59150</td>\n",
              "      <td>Toddler miraculously survives 6-story fall lan...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59151 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6da665ec-e6c8-46aa-a0d6-ac531dfba68a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6da665ec-e6c8-46aa-a0d6-ac531dfba68a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6da665ec-e6c8-46aa-a0d6-ac531dfba68a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "#showing the testing data\n",
        "df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfjAEatrMKG-",
        "outputId": "6683b286-7094-44c4-9d77-94df5f44eaa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 60000 entries, 265723 to 34509\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    60000 non-null  object\n",
            " 1   label   60000 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 1.4+ MB\n"
          ]
        }
      ],
      "source": [
        "# show the information of the train dataset\n",
        "df_train.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBlck_BYMSCu",
        "outputId": "7723368a-07ba-4ca0-c5ae-36ec15522575"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 59151 entries, 0 to 59150\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      59151 non-null  int64 \n",
            " 1   text    59151 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 924.4+ KB\n"
          ]
        }
      ],
      "source": [
        "# show the information of the test dataset\n",
        "df_test.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWIu1yiBMcm-"
      },
      "source": [
        "#Data Cleaning and Preprocessing\n",
        "Data cleaning is the process of fixing or removing incorrect, corrupted, incorrectly formatted, duplicate, or incomplete data within a dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFCwwT_6MU19",
        "outputId": "deb0b56f-c0b6-4090-b179-4c6c7d0e3092"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "# check if there any missing values and counting them for each feature\n",
        "df_train.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJuxC33rM50O",
        "outputId": "912ae225-2457-4da7-cc7a-3f6c5abc2372"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# show the sum of null values in rating \n",
        "df_train.isna().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mG3oqG6eNCjX",
        "outputId": "abc815f2-a9d6-4504-a5b9-00561a4554c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id      0\n",
              "text    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "# check if there any missing values and counting them for each feature\n",
        "df_test.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rkn4alu2NF23",
        "outputId": "5a2c4e26-b459-498f-bde9-33833ed140f1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "# show the sum of null values in rating \n",
        "df_test.isna().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cwNVw12WNIgX",
        "outputId": "138f51f1-9528-4bdb-c644-005a0d3833d8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "345"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "#check the duplicated values in training data\n",
        "df_train.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0myL-4W5NK9R",
        "outputId": "e56450b6-f5b8-4aca-de24-2aa258c8bafb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "#check the duplicated values in testing data\n",
        "df_test.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "B0Whpah8RIX4"
      },
      "outputs": [],
      "source": [
        "# Drop duplicate rows\n",
        "df_train.drop_duplicates(subset='text', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kYkKYkxlNyC3",
        "outputId": "206df095-5abf-4024-e863-c3c720ce9af5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "#check the duplicated values in training data\n",
        "df_train.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hq5CHtl3N2nN",
        "outputId": "4cc43558-3885-4ee2-d232-474f0868c581"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "#check if the label column contains label of 2 or not \n",
        "2 in df_train['label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h1fPAtpN6Qt",
        "outputId": "1a0749db-0e9b-416c-d1fe-6687c3549fbc"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    31949\n",
              "1    27696\n",
              "Name: new_label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "#replace label 2 with label 1\n",
        "df_train[\"new_label\"] = 0\n",
        "df_train.loc[df_train[\"label\"] == 0, \"new_label\"] = 0\n",
        "df_train.loc[df_train[\"label\"] > 0, \"new_label\"] = 1\n",
        "\n",
        "#checking for the distribution of grade_bad\n",
        "df_train['new_label'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dd7I9HZNOMUu",
        "outputId": "e74c72c1-89cf-45cf-9ab0-265aca8b0b7f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59645, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "\n",
        "#display new data shape\n",
        "df_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp_vnCUCGcYH"
      },
      "source": [
        "#text processing using NLTK\n",
        "The Natural Language Toolkit (NLTK) is a platform used for building Python programs that work with human language data for applying in statistical natural language processing (NLP)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v1s1_yzGOpH9",
        "outputId": "60a628f6-9c63-4690-c15a-2a95c17c36ab"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt') #This tokenizer divides a text into a list of sentences by using an unsupervised algorithm to build a model for abbreviation words, collocations, and words that start sentences.\n",
        "nltk.download('stopwords')  # In NLP and text mining applications, stop words are used to eliminate unimportant words, allowing applications to focus on the important words instead.\n",
        "lemmatizer = WordNetLemmatizer()  #Lemmatization is the process of grouping together the different inflected forms of a word so they can be analyzed as a single item.\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "\n",
        "def clean_text(text, for_embedding=False):\n",
        "\n",
        "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "    RE_TAGS = re.compile(r\"<[^>]+>\")\n",
        "    RE_ASCII = re.compile(r\"[^A-Za-zA-z ]\", re.IGNORECASE)\n",
        "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zA-z]\\b\", re.IGNORECASE)\n",
        "    if for_embedding:\n",
        "        # Keep punctuation\n",
        "        RE_ASCII = re.compile(r\"[^A-Za-zA-z,.!? ]\", re.IGNORECASE)\n",
        "        RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zA-z,.!?]\\b\", re.IGNORECASE)\n",
        "\n",
        "    text = re.sub(RE_TAGS, \" \", text)\n",
        "    text = re.sub(RE_ASCII, \" \", text)\n",
        "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
        "    text = re.sub(RE_WSPACE, \" \", text)\n",
        "    #use textblob to correct spelling mistakes\n",
        "    #m = TextBlob(text)\n",
        "    #text=m.correct()\n",
        "\n",
        "    #divide rows into sentences(tokens) to be easier to understod\n",
        "    word_tokens = word_tokenize(text)\n",
        "    words_tokens_lower = [word.lower() for word in word_tokens]\n",
        "\n",
        "    if for_embedding:\n",
        "        # no lemmatizing, lowering and punctuation / stop words removal\n",
        "        words_filtered = word_tokens\n",
        "    else:\n",
        "        words_filtered = [\n",
        "            lemmatizer.lemmatize(word) for word in words_tokens_lower if word not in stop_words\n",
        "        ]\n",
        "\n",
        "    text_clean = \" \".join(words_filtered)\n",
        "    return text_clean"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QnFyQ4lOPmCu",
        "outputId": "4f51255b-717a-4c33-f2f7-74886e5d2f00"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count                                                 59645\n",
              "unique                                                59645\n",
              "top       A group of friends began to volunteer at a hom...\n",
              "freq                                                      1\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "df_train.text.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VirLgi9MPoim",
        "outputId": "9689257b-7098-4ec1-c756-245e11e47a34"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.535653\n",
              "1    0.464347\n",
              "Name: new_label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "\n",
        "#check if train data balanced or not\n",
        "df_train[\"new_label\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVIvT8nFPwbO",
        "outputId": "90c9218d-89f3-42e7-ef09-e1ba1e118ddd"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(id\n",
              " 265723    A group of friends began to volunteer at a hom...\n",
              " 284269    British Prime Minister @Theresa_May on Nerve A...\n",
              " 207715    In 1961, Goodyear released a kit that allows P...\n",
              " 551106    Happy Birthday, Bob Barker! The Price Is Right...\n",
              " 8584      Obama to Nation: 聙\"Innocent Cops and Unarmed Y...\n",
              "                                 ...                        \n",
              " 70046     Finish Sniper Simo H盲yh盲 during the invasion o...\n",
              " 189377    Nigerian Prince Scam took $110K from Kansas ma...\n",
              " 93486     Is It Safe To Smoke Marijuana During Pregnancy...\n",
              " 140950    Julius Caesar upon realizing that everyone in ...\n",
              " 34509     Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New...\n",
              " Name: text, Length: 59645, dtype: object,\n",
              " id\n",
              " 265723    0\n",
              " 284269    0\n",
              " 207715    0\n",
              " 551106    0\n",
              " 8584      0\n",
              "          ..\n",
              " 70046     0\n",
              " 189377    1\n",
              " 93486     0\n",
              " 140950    0\n",
              " 34509     1\n",
              " Name: new_label, Length: 59645, dtype: int64,\n",
              " 0                                               stargazer \n",
              " 1                                                     yeah\n",
              " 2        PD: Phoenix car thief gets instructions from Y...\n",
              " 3        As Trump Accuses Iran, He Has One Problem: His...\n",
              " 4                             \"Believers\" - Hezbollah 2011\n",
              "                                ...                        \n",
              " 59146                    Bicycle taxi drivers of New Delhi\n",
              " 59147    Trump blows up GOP's formula for winning House...\n",
              " 59148    Napoleon returns from his exile on the island ...\n",
              " 59149     Deep down he always wanted to be a ballet dancer\n",
              " 59150    Toddler miraculously survives 6-story fall lan...\n",
              " Name: text, Length: 59151, dtype: object)"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "\n",
        "#split columns\n",
        "test=df_test['text']\n",
        "x=df_train['text']\n",
        "y=df_train['new_label']\n",
        "x,y,test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "1to6kkcUXDvY"
      },
      "outputs": [],
      "source": [
        "# Further split the original training set to a train and a validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(x, y, train_size = 0.8, stratify = y, random_state = 2022)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkYYHRDyVxBH"
      },
      "source": [
        "#model building "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "*   the usage of grid search is if we had to select the values for two or more \n",
        "parameters, we would evaluate all combinations of the sets of values thus forming a grid of values and take the best one.\n",
        "\n",
        "\n",
        "*  the usage of Logistic regression is to solve classification problems . It does this by predicting categorical outcomes, unlike linear regression that predicts a continuous outcome. \n",
        "\n",
        "\n",
        "\n",
        "*   the Bayesian optimization is an informed search method, meaning that it learns from previous iterations\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*    The multinomial Naive Bayes classifier is suitable for classification with discrete features (e.g., word counts for text classification). The multinomial distribution normally requires integer feature counts. However, in practice, fractional counts such as tf-idf may also work.\n",
        "\n",
        "*   Random forests can be used for solving regression (numeric target variable) and classification (categorical target variable) problems. Random forests are an ensemble method, meaning they combine predictions from other models. Each of the smaller models in the random forest ensemble is a decision tree.\n",
        "\n",
        "\n",
        "\n",
        "*   XGBoost is a popular and efficient open-source implementation of the gradient boosted trees algorithm. Gradient boosting is a supervised learning algorithm, which attempts to accurately predict a target variable by combining the estimates of a set of simpler, weaker models. \n",
        "\n",
        "  the advandage of it is that it uses aggregation function \n",
        "\n",
        "*   MLPClassifier implements a multi-layer perceptron (MLP) algorithm that trains using Backpropagation. Currently, MLPClassifier supports only the Cross-Entropy loss function, which allows probability estimates by running the predict_proba method.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "*   the usage of word vectorizer is to convert words to vectors, or word vectorization, is a natural language processing (NLP) process. The process uses language models to map words into vector space. A vector space represents each word by a vector of real numbers. It also allows words with similar meanings have similar representations\n",
        "\n",
        "\n",
        "*   The purpose of word or character vectorization was to transform sentences or documents into feature sets that could be used for machine learning.\n",
        "So vectorization refers to the general process of converting text or characters to a vector representation while embedding refers to learning the vectorization through deep learning (often through an embedding layer)\n",
        "\n"
      ],
      "metadata": {
        "id": "gKHrvRBcFNIM"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sFS8PbE2W5G_"
      },
      "source": [
        "Trial 1\n",
        "\n",
        "Use pipeline with GridSearch, validation set and logistic regression model with word-level vectorizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "604cKJcaBHGu",
        "outputId": "2fb277b7-3c73-40c9-8b3f-71d91ed9d1ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('omw-1.4')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mFpF56ccP8Vd",
        "outputId": "b193b7d6-ae17-425c-8451-d84eee3732e3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
            "9 fits failed out of a total of 18.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "9 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.82969702        nan 0.85442143        nan 0.86923623\n",
            "        nan 0.69051047        nan 0.69708601        nan 0.70109502\n",
            "        nan 0.83107329        nan 0.8567113         nan 0.87355495]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train score 0.9201049469656826\n",
            "Best params: {'cvec__ngram_range': (1, 3), 'lr__C': 1, 'lr__penalty': 'l2'}\n"
          ]
        }
      ],
      "source": [
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "split_index = [-1 if i in X_train.index else 0 for i in x.index]\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)\n",
        "\n",
        "#set vectorizer hyperparameters\n",
        "pipe = Pipeline([('cvec', TfidfVectorizer(preprocessor=clean_text,analyzer=\"word\", max_df=0.3, min_df=10, norm=\"l2\")),    \n",
        "                 ('lr', LogisticRegression(solver='sag'))])\n",
        "# Tune GridSearchCV\n",
        "pipe_params = {'cvec__ngram_range': [(1,1), (2,2), (1,3)],'lr__C': [0.01, 0.1,1], 'lr__penalty': ['l1', 'l2']}\n",
        "gs = GridSearchCV(pipe, param_grid=pipe_params,  scoring=\"roc_auc\", cv=pds)\n",
        "#train model with gridsearchcv\n",
        "gs.fit(x, y);\n",
        "#predict best score and params\n",
        "print(\"Train score\", gs.score(x, y))\n",
        "print(\"Best params:\", gs.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "after observations I think logsitic classifier is good one"
      ],
      "metadata": {
        "id": "EVUDz5jCtJWn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UkjFIw2wXK3u"
      },
      "outputs": [],
      "source": [
        "#predict output and save submission\n",
        "submission = pd.DataFrame()\n",
        "submission['id'] = df_test['id']\n",
        "submission['label']=gs.predict_proba(test)[:,1]\n",
        "submission.to_csv('logistic_with_gridsearch.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QkPFu6A7ZYTP"
      },
      "source": [
        "**Trial 2**\n",
        "\n",
        "Use MultinominalNB with word analyzer and Gridsearch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nu8pxUQHZZw-",
        "outputId": "33b9a7f5-c3bb-4695-fbdf-6c0adbfa0356"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train score 0.8963220233434934\n",
            "Best params: {'cvec__ngram_range': (1, 3), 'nb__alpha': 1}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "#set vectorizer hyperparameters\n",
        "pipe = Pipeline([('cvec', TfidfVectorizer(preprocessor=clean_text,analyzer=\"word\", max_df=0.3, min_df=10, norm=\"l2\")),    \n",
        "                 ('nb', MultinomialNB())])\n",
        "# Tune GridSearchCV\n",
        "pipe_params = {'cvec__ngram_range': [(1,1), (2,2), (1,3)],\n",
        "               'nb__alpha': [0.001, 0.01, 0.1, 1, 10, 100]}\n",
        "gs = GridSearchCV(estimator=pipe, param_grid=pipe_params,  scoring=\"roc_auc\", cv=pds)\n",
        "#train model with gridsearchcv\n",
        "gs.fit(x, y);\n",
        "#predict best score and params\n",
        "print(\"Train score\", gs.score(x, y))\n",
        "print(\"Best params:\", gs.best_params_)\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "after observations I think Multinomial is good one too"
      ],
      "metadata": {
        "id": "Ur4ASI4StRcC"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9bXe4YSvbLEx"
      },
      "source": [
        "**Trial 3**\n",
        "\n",
        "\n",
        "Model with randomForest, character-level vectorizer and GridSearch with validation set\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHn2Bux7Zgu_",
        "outputId": "87bbbbb5-8149-4625-bd47-8ae86b4b8440"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Train score 0.9751859714443435\n",
            "Best params: {'rf__max_depth': 1000, 'rf__max_leaf_nodes': None, 'rf__min_samples_split': 100, 'tvec__max_features': 2000, 'tvec__ngram_range': (1, 2), 'tvec__stop_words': 'english'}\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Randomforest pipeline setup\n",
        "rf_pipe = Pipeline([('tvec',  TfidfVectorizer(preprocessor=clean_text,analyzer=\"char\", max_df=0.3, min_df=10, norm=\"l2\")),\n",
        "                    ('rf', RandomForestClassifier())])\n",
        "# Setting up randomforest params\n",
        "rf_params = {'tvec__max_features':[2000],'tvec__ngram_range': [(1, 2)],'tvec__stop_words': ['english'],\n",
        "             'rf__max_depth': [1000],'rf__min_samples_split': [100],'rf__max_leaf_nodes': [None]}\n",
        "             \n",
        "rf_pipe.fit(x, y)\n",
        "# Setting up GridSearch for TFIDFVectorizer\n",
        "rf_gs = GridSearchCV(rf_pipe, param_grid=rf_params, scoring=\"roc_auc\", cv = pds, verbose = 1, n_jobs = -1)\n",
        "# Fitting Randomforest CV GS\n",
        "rf_gs.fit(x, y)\n",
        "#predict best score\n",
        "print(\"Train score\", rf_gs.score(x, y))\n",
        "print(\"Best params:\", rf_gs.best_params_)\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "after observations I think random forest is overfitting "
      ],
      "metadata": {
        "id": "gOl0pRUStdw7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TofbOakPbRzf"
      },
      "outputs": [],
      "source": [
        "\n",
        "#predict output and save submission\n",
        "submission = pd.DataFrame()\n",
        "submission['id'] = df_test['id']\n",
        "submission['label']=rf_gs.predict_proba(test)[:,1]\n",
        "submission.to_csv('randomForest_gridsearch.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJPfCSQUcy-b"
      },
      "source": [
        "**Trial 4**\n",
        "\n",
        "\n",
        "XGBoost Model with grid search and word-level vectorizer with validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3JWpS2L5cldv",
        "outputId": "6c43e95b-93b2-4ccc-951c-9a9d1d61f661"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 18 candidates, totalling 18 fits\n",
            "best score 0.8438191020508723\n",
            "best score {'cvec__ngram_range': (1, 3), 'my_classifier__max_depth': 30}\n"
          ]
        }
      ],
      "source": [
        "# combine the preprocessor with the model as a full tunable pipeline\n",
        "# we gave them a name so we can set their hyperparameters\n",
        "full_pipline = Pipeline(steps=[('cvec', TfidfVectorizer(preprocessor=clean_text,analyzer=\"char\", max_df=0.3, min_df=10, norm=\"l2\")), \n",
        "                                 ('my_classifier', XGBClassifier(n_estimators=200, colsample_bytree=0.8, \n",
        "                        subsample=0.8, nthread=10, learning_rate=0.1))])\n",
        "full_pipline.fit(x,y)\n",
        "param_grid = {'cvec__ngram_range': [(1,1), (2,2), (1,3)],\n",
        "             'my_classifier__max_depth':[5,10, 20, 30,40,50] }\n",
        "\n",
        "grid_xg = GridSearchCV(full_pipline, param_grid=param_grid, scoring=\"roc_auc\", cv = pds, verbose = 1, n_jobs = -1)\n",
        "grid_xg.fit(x, y)\n",
        "#predict best score\n",
        "print('best score {}'.format(grid_xg.best_score_))\n",
        "print('best score {}'.format(grid_xg.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "after observations I think XGBoost is likely to be good too"
      ],
      "metadata": {
        "id": "fcqo1Wm6tz90"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64dZ5_LZgSiJ"
      },
      "source": [
        "**Trial 5**\n",
        "\n",
        "MLP classifier with word level vectorizer and gridsearchcv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ywV0FCRc4-f",
        "outputId": "94130b05-274c-4ef5-93b0-39e662c4b991"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 3 candidates, totalling 3 fits\n",
            "best score 0.8514583458706947\n",
            "best score {'cvec__ngram_range': (1, 3)}\n"
          ]
        }
      ],
      "source": [
        "full_pipline_5 = Pipeline(steps=[('cvec', TfidfVectorizer(preprocessor=clean_text,analyzer=\"word\", max_df=0.3, min_df=10, norm=\"l2\")), \n",
        "                                 ('my_classifier',MLPClassifier(random_state=1,solver=\"adam\",\n",
        "                                  hidden_layer_sizes=(224, 120, 12,),activation=\"relu\",n_iter_no_change=10))])\n",
        "\n",
        "param_grid_5 = {'cvec__ngram_range': [(1,1), (2,2), (1,3)]}\n",
        "grid_mlp = GridSearchCV(full_pipline_5,param_grid_5,scoring=\"roc_auc\", cv = pds, verbose = 1, n_jobs = -1)\n",
        "grid_mlp.fit(x, y)\n",
        "#predict best score\n",
        "print('best score {}'.format(grid_mlp.best_score_))\n",
        "print('best score {}'.format(grid_mlp.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "after observations I think MLP classifier is likely to be good too"
      ],
      "metadata": {
        "id": "AXNv3Z6Mt-Ux"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0zghan9Vuk9W"
      },
      "source": [
        "#**scenario_2**\n",
        "\n",
        "Stemming is a natural language processing technique that is used to reduce words to their base form, also known as the root form."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fDl9fGlvP0S"
      },
      "source": [
        "#load data\n",
        "The built-in function open() accepts two arguments: file name and mode, and it can be used to read from and write to files."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "I'll use the read csv function to read the data."
      ],
      "metadata": {
        "id": "CB02PMdlGwau"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "XpqcpMxGuoH-"
      },
      "outputs": [],
      "source": [
        "#load the training and testing data\n",
        "df_train2= pd.read_csv('xy_train.csv',index_col='id')\n",
        "df_test2 = pd.read_csv('x_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "tJ6VDNsgu65e",
        "outputId": "f5c58e52-4e11-4c23-f0b4-df3a2360a443"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                     text  label\n",
              "id                                                              \n",
              "265723  A group of friends began to volunteer at a hom...      0\n",
              "284269  British Prime Minister @Theresa_May on Nerve A...      0\n",
              "207715  In 1961, Goodyear released a kit that allows P...      0\n",
              "551106  Happy Birthday, Bob Barker! The Price Is Right...      0\n",
              "8584    Obama to Nation: 聙\"Innocent Cops and Unarmed Y...      0\n",
              "...                                                   ...    ...\n",
              "70046   Finish Sniper Simo H盲yh盲 during the invasion o...      0\n",
              "189377  Nigerian Prince Scam took $110K from Kansas ma...      1\n",
              "93486   Is It Safe To Smoke Marijuana During Pregnancy...      0\n",
              "140950  Julius Caesar upon realizing that everyone in ...      0\n",
              "34509   Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New...      1\n",
              "\n",
              "[60000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab0b5de6-ee9e-4c3b-a07f-c2c5bbde2c44\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>265723</th>\n",
              "      <td>A group of friends began to volunteer at a hom...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284269</th>\n",
              "      <td>British Prime Minister @Theresa_May on Nerve A...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207715</th>\n",
              "      <td>In 1961, Goodyear released a kit that allows P...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551106</th>\n",
              "      <td>Happy Birthday, Bob Barker! The Price Is Right...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8584</th>\n",
              "      <td>Obama to Nation: 聙\"Innocent Cops and Unarmed Y...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70046</th>\n",
              "      <td>Finish Sniper Simo H盲yh盲 during the invasion o...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189377</th>\n",
              "      <td>Nigerian Prince Scam took $110K from Kansas ma...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93486</th>\n",
              "      <td>Is It Safe To Smoke Marijuana During Pregnancy...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140950</th>\n",
              "      <td>Julius Caesar upon realizing that everyone in ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34509</th>\n",
              "      <td>Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>60000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab0b5de6-ee9e-4c3b-a07f-c2c5bbde2c44')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab0b5de6-ee9e-4c3b-a07f-c2c5bbde2c44 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab0b5de6-ee9e-4c3b-a07f-c2c5bbde2c44');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "#showing the training data\n",
        "df_train2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "7IDv2I81u_Pj",
        "outputId": "aafea6ea-d5fb-40dc-d508-82cba299dbd8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          id                                               text\n",
              "0          0                                         stargazer \n",
              "1          1                                               yeah\n",
              "2          2  PD: Phoenix car thief gets instructions from Y...\n",
              "3          3  As Trump Accuses Iran, He Has One Problem: His...\n",
              "4          4                       \"Believers\" - Hezbollah 2011\n",
              "...      ...                                                ...\n",
              "59146  59146                  Bicycle taxi drivers of New Delhi\n",
              "59147  59147  Trump blows up GOP's formula for winning House...\n",
              "59148  59148  Napoleon returns from his exile on the island ...\n",
              "59149  59149   Deep down he always wanted to be a ballet dancer\n",
              "59150  59150  Toddler miraculously survives 6-story fall lan...\n",
              "\n",
              "[59151 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-884481d7-f674-4701-99be-0f083c4c7c7c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>stargazer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>yeah</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>PD: Phoenix car thief gets instructions from Y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>As Trump Accuses Iran, He Has One Problem: His...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>\"Believers\" - Hezbollah 2011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59146</th>\n",
              "      <td>59146</td>\n",
              "      <td>Bicycle taxi drivers of New Delhi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59147</th>\n",
              "      <td>59147</td>\n",
              "      <td>Trump blows up GOP's formula for winning House...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59148</th>\n",
              "      <td>59148</td>\n",
              "      <td>Napoleon returns from his exile on the island ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59149</th>\n",
              "      <td>59149</td>\n",
              "      <td>Deep down he always wanted to be a ballet dancer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59150</th>\n",
              "      <td>59150</td>\n",
              "      <td>Toddler miraculously survives 6-story fall lan...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>59151 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-884481d7-f674-4701-99be-0f083c4c7c7c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-884481d7-f674-4701-99be-0f083c4c7c7c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-884481d7-f674-4701-99be-0f083c4c7c7c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ],
      "source": [
        "#showing the testing data\n",
        "df_test2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bs3joun7vCr5",
        "outputId": "30e5b386-5fb7-4aee-d7bf-caff4a708e81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 60000 entries, 265723 to 34509\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   text    60000 non-null  object\n",
            " 1   label   60000 non-null  int64 \n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 1.4+ MB\n"
          ]
        }
      ],
      "source": [
        "# show the information of the train dataset\n",
        "df_train2.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nvo4qhHGvHHv",
        "outputId": "2df0e30b-844b-48e8-fb2f-9a307f2b97af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 59151 entries, 0 to 59150\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   id      59151 non-null  int64 \n",
            " 1   text    59151 non-null  object\n",
            "dtypes: int64(1), object(1)\n",
            "memory usage: 924.4+ KB\n"
          ]
        }
      ],
      "source": [
        "# show the information of the test dataset\n",
        "df_test2.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QvvZqctXvWbU"
      },
      "source": [
        "#Data Cleaning and Preprocessing\n",
        "The process of correcting or removing inaccurate, damaged, improperly formatted, duplicate, or incomplete data from a dataset is known as data cleaning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AI_mVvmUvchi",
        "outputId": "514e6b22-e68f-4381-dff0-ad0cdb6d6fb3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text     0\n",
              "label    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "# check if there any missing values and counting them for each feature\n",
        "df_train2.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXmudbjtvmah",
        "outputId": "ac6b149e-1dc3-41f0-82ad-dc9da270b80e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ],
      "source": [
        "# show the sum of null values in rating \n",
        "df_train2.isna().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G1pkTGsnvvwU",
        "outputId": "fc996539-1034-415d-a739-37e218d36475"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id      0\n",
              "text    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# check if there any missing values and counting them for each feature\n",
        "df_test2.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "os8C1oxkv3oC",
        "outputId": "3fd3f93b-efd3-4d88-d46a-c178193a29b8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# show the sum of null values in rating \n",
        "df_test2.isna().sum().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXTnokD5v8nu",
        "outputId": "a549adf2-76ab-440b-851b-9ed1ac56c54e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "345"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "#check the duplicated values in training data\n",
        "df_train2.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BtSKrY1WwDTg",
        "outputId": "0a1cd902-0ecb-4853-990d-c0fe42b90618"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ],
      "source": [
        "#check the duplicated values in testing data\n",
        "df_test2.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "jWFiyMEiwKwZ"
      },
      "outputs": [],
      "source": [
        "# Drop duplicate rows\n",
        "df_train2.drop_duplicates(subset='text', inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NlwSzC9UwPea",
        "outputId": "94885a35-4d6a-41e5-80fa-ab57077c6d87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "#check the duplicated values in training data\n",
        "df_train2.duplicated().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vOG2nL71wTqq",
        "outputId": "c9272094-f334-4405-8c89-0bce31d288b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "#check if the label column contains label of 2 or not \n",
        "2 in df_train2['label'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60gnzIj1wZpF",
        "outputId": "af1ca612-e6f9-4d41-baa1-295d1aef5f0e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    31949\n",
              "1    27696\n",
              "Name: new_label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ],
      "source": [
        "#replace label 2 with label 1\n",
        "df_train2[\"new_label\"] = 0\n",
        "df_train2.loc[df_train2[\"label\"] == 0, \"new_label\"] = 0\n",
        "df_train2.loc[df_train2[\"label\"] > 0, \"new_label\"] = 1\n",
        "\n",
        "#checking for the distribution of grade_bad\n",
        "df_train2['new_label'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#text processing using NLTK\n",
        "The Natural Language Toolkit (NLTK) is a platform used for building Python programs that work with human language data for applying in statistical natural language processing (NLP)"
      ],
      "metadata": {
        "id": "Lf2vJcl5H7k9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-9KDSwhTwmF3",
        "outputId": "c39e31e4-e5fe-4557-e853-d1d4b9ed9a51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stemmer = SnowballStemmer(\"english\")   # It is the method used to return the word to its original form\n",
        "stop_words = set(stopwords.words(\"english\")) # It is the method of producing a stop words\n",
        "\n",
        "def clean_text(text, for_embedding=False):\n",
        "    \"\"\" steps:\n",
        "        - remove any html tags (< /br> often found)\n",
        "        - Keep only ASCII + European Chars and whitespace, no digits\n",
        "        - remove single letter chars\n",
        "        - convert all whitespaces (tabs etc.) to single wspace\n",
        "        if not for embedding (but e.g. tdf-idf):\n",
        "        - all lowercase\n",
        "        - remove stopwords, punctuation and stemm\n",
        "    \"\"\"\n",
        "    # IGNORECASE : is a flag allows for case-insensitive matching of the Regular Expression with the given string\n",
        "     # Remove any more than one space\n",
        "    RE_WSPACE = re.compile(r\"\\s+\", re.IGNORECASE)\n",
        "   # Remove web tags\n",
        "    RE_TAGS = re.compile(r\"<[^>]+>\") \n",
        "    # Remove any leter does not english charachter\n",
        "    RE_ASCII = re.compile(r\"[^A-Za-zA-z ]\", re.IGNORECASE) \n",
        "    # Remove any single character\n",
        "    RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zA-z]\\b\", re.IGNORECASE) \n",
        "    if for_embedding:\n",
        "        # Keep punctuation\n",
        "        RE_ASCII = re.compile(r\"[^A-Za-zA-z,.!? ]\", re.IGNORECASE)\n",
        "        RE_SINGLECHAR = re.compile(r\"\\b[A-Za-zA-z,.!?]\\b\", re.IGNORECASE)\n",
        "    # Replace any tag with a single space.\n",
        "    text = re.sub(RE_TAGS, \" \", text)\n",
        "    # Replace any non english character with a single space.\n",
        "    text = re.sub(RE_ASCII, \" \", text)\n",
        "    # Replace any single character with a single space.\n",
        "    text = re.sub(RE_SINGLECHAR, \" \", text)\n",
        "    # Replace any more than one space with a single space.\n",
        "    text = re.sub(RE_WSPACE, \" \", text)  \n",
        "   \n",
        "    # split the sentence into words\n",
        "    word_tokens = word_tokenize(text) \n",
        "    # Convert all letters to small letters\n",
        "    words_tokens_lower = [word.lower() for word in word_tokens] \n",
        "\n",
        "    # words_filtered (Words can be filtered based on how many times they appear)\n",
        "    # stemmer used to return the word to its original form.\n",
        "    words_filtered = [\n",
        "        stemmer.stem(word) for word in words_tokens_lower if word not in stop_words\n",
        "    ]\n",
        "\n",
        "    # Join all words in text_clean and separate them by space.\n",
        "    text_clean2 = \" \".join(words_filtered)\n",
        "    return text_clean2\n",
        "     "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "66k7zZ6Yzde0",
        "outputId": "56943cd2-9d66-4617-f398-635dde9216e8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    0.535653\n",
              "1    0.464347\n",
              "Name: new_label, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ],
      "source": [
        "#check if train data balanced or not\n",
        "df_train2[\"new_label\"].value_counts(normalize=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-HS4dayH11cq",
        "outputId": "98e9c59b-69e4-4958-f341-ed67a49ce7ad"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(id\n",
              " 265723    A group of friends began to volunteer at a hom...\n",
              " 284269    British Prime Minister @Theresa_May on Nerve A...\n",
              " 207715    In 1961, Goodyear released a kit that allows P...\n",
              " 551106    Happy Birthday, Bob Barker! The Price Is Right...\n",
              " 8584      Obama to Nation: 聙\"Innocent Cops and Unarmed Y...\n",
              "                                 ...                        \n",
              " 70046     Finish Sniper Simo H盲yh盲 during the invasion o...\n",
              " 189377    Nigerian Prince Scam took $110K from Kansas ma...\n",
              " 93486     Is It Safe To Smoke Marijuana During Pregnancy...\n",
              " 140950    Julius Caesar upon realizing that everyone in ...\n",
              " 34509     Jeff Bridges Releasing 鈥楽leeping Tapes,鈥?a New...\n",
              " Name: text, Length: 59645, dtype: object,\n",
              " id\n",
              " 265723    0\n",
              " 284269    0\n",
              " 207715    0\n",
              " 551106    0\n",
              " 8584      0\n",
              "          ..\n",
              " 70046     0\n",
              " 189377    1\n",
              " 93486     0\n",
              " 140950    0\n",
              " 34509     1\n",
              " Name: new_label, Length: 59645, dtype: int64,\n",
              " 0                                               stargazer \n",
              " 1                                                     yeah\n",
              " 2        PD: Phoenix car thief gets instructions from Y...\n",
              " 3        As Trump Accuses Iran, He Has One Problem: His...\n",
              " 4                             \"Believers\" - Hezbollah 2011\n",
              "                                ...                        \n",
              " 59146                    Bicycle taxi drivers of New Delhi\n",
              " 59147    Trump blows up GOP's formula for winning House...\n",
              " 59148    Napoleon returns from his exile on the island ...\n",
              " 59149     Deep down he always wanted to be a ballet dancer\n",
              " 59150    Toddler miraculously survives 6-story fall lan...\n",
              " Name: text, Length: 59151, dtype: object)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "#split columns\n",
        "test=df_test2['text']\n",
        "x=df_train2['text']\n",
        "y=df_train2['new_label']\n",
        "x,y,test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "zFF_quMr2Kmg"
      },
      "outputs": [],
      "source": [
        "# Further split the original training set to a train and a validation set\n",
        "X_train, X_val, y_train, y_val = train_test_split(x, y, train_size = 0.8, stratify = y, random_state = 2022)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yRvexMEx3cfM"
      },
      "source": [
        "#modeling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K_oqUeee3fWr"
      },
      "source": [
        "Trial 1\n",
        "\n",
        "Use pipeline with GridSearch, validation set and logistic regression model with word-level vectorizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7PKqh8zT3oYe",
        "outputId": "db992659-df19-4e8d-bfb4-6f773ac1840c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:372: FitFailedWarning: \n",
            "9 fits failed out of a total of 18.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "9 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 680, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\sklearn\\pipeline.py\", line 394, in fit\n",
            "    self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
            "  File \"C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1461, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "  File \"C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 447, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:969: UserWarning: One or more of the test scores are non-finite: [       nan 0.82893025        nan 0.85330127        nan 0.86754654\n",
            "        nan 0.70092288        nan 0.70766113        nan 0.71053996\n",
            "        nan 0.83067368        nan 0.85599957        nan 0.87259395]\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train score 0.9141286942655702\n",
            "Best params: {'cvec__ngram_range': (1, 3), 'lr__C': 1, 'lr__penalty': 'l2'}\n"
          ]
        }
      ],
      "source": [
        "# Create a list where train data indices are -1 and validation data indices are 0\n",
        "split_index = [-1 if i in X_train.index else 0 for i in x.index]\n",
        "# Use the list to create PredefinedSplit\n",
        "pds = PredefinedSplit(test_fold = split_index)\n",
        "\n",
        "#set vectorizer hyperparameters\n",
        "pipe = Pipeline([('cvec', TfidfVectorizer(preprocessor=clean_text,analyzer=\"word\", max_df=0.3, min_df=10, norm=\"l2\")),    \n",
        "                 ('lr', LogisticRegression(solver='sag'))])\n",
        "# Tune GridSearchCV\n",
        "pipe_params = {'cvec__ngram_range': [(1,1), (2,2), (1,3)],'lr__C': [0.01, 0.1,1], 'lr__penalty': ['l1', 'l2']}\n",
        "gs = GridSearchCV(pipe, param_grid=pipe_params,  scoring=\"roc_auc\", cv=pds)\n",
        "#train model with gridsearchcv\n",
        "gs.fit(x, y);\n",
        "#predict best score and params\n",
        "print(\"Train score\", gs.score(x, y))\n",
        "print(\"Best params:\", gs.best_params_)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "after observations I think logisitic regression with gridsearch is good one"
      ],
      "metadata": {
        "id": "dwbxdJ9Tu0bk"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "80ZuFNMH5reY"
      },
      "source": [
        "Trial 2\n",
        "\n",
        "XGBoost Model with bayesian search and word-level vectorizer with validation set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 553
        },
        "id": "xlfKbWyc3qD3",
        "outputId": "8d7f680b-fd3b-43a2-b22d-d342e70a8b58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: scikit-optimize in c:\\users\\lap-5\\anaconda3\\lib\\site-packages (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\lap-5\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.21.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\lap-5\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: joblib>=0.11 in c:\\users\\lap-5\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.1.0)\n",
            "Requirement already satisfied: pyaml>=16.9 in c:\\users\\lap-5\\anaconda3\\lib\\site-packages (from scikit-optimize) (21.10.1)\n",
            "Requirement already satisfied: scipy>=0.19.1 in c:\\users\\lap-5\\anaconda3\\lib\\site-packages (from scikit-optimize) (1.9.1)\n",
            "Requirement already satisfied: PyYAML in c:\\users\\lap-5\\anaconda3\\lib\\site-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\lap-5\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->scikit-optimize) (2.2.0)\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Lap-5\\anaconda3\\lib\\site-packages\\skopt\\optimizer\\optimizer.py:449: UserWarning: The objective has been evaluated at this point before.\n",
            "  warnings.warn(\"The objective has been evaluated \"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 1 folds for each of 1 candidates, totalling 1 fits\n",
            "best score 0.75657374468875\n",
            "best score OrderedDict([('my_classifier__max_depth', 30)])\n"
          ]
        }
      ],
      "source": [
        "!pip install scikit-optimize\n",
        "import skopt\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "# combine the preprocessor with the model as a full tunable pipeline\n",
        "# we gave them a name so we can set their hyperparameters\n",
        "full_pipline = Pipeline(steps=[('cvec', TfidfVectorizer(preprocessor=clean_text,analyzer=\"char\", max_df=0.3, min_df=10, norm=\"l2\",ngram_range=(1,2))), \n",
        "                                 ('my_classifier', XGBClassifier(n_estimators=200, colsample_bytree=0.8, \n",
        "                        subsample=0.8, nthread=10, learning_rate=0.1))])\n",
        "full_pipline.fit(x,y)\n",
        "param_grid = {'my_classifier__max_depth':[5,10, 20, 30] }\n",
        "grid_xg = BayesSearchCV(full_pipline,  param_grid, scoring=\"roc_auc\", cv = pds, verbose = 1, n_jobs = -1)\n",
        "grid_xg.fit(x, y)\n",
        "#predict best score\n",
        "print('best score {}'.format(grid_xg.best_score_))\n",
        "print('best score {}'.format(grid_xg.best_params_))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "after observations I think XGBOOST with bayesian search is not that good "
      ],
      "metadata": {
        "id": "DFgkAQ6v0vem"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ajud1iet02_O"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "gESwe_xtKaRn",
        "xkYYHRDyVxBH",
        "3fDl9fGlvP0S",
        "QvvZqctXvWbU",
        "Lf2vJcl5H7k9"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}